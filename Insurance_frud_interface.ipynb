{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namyaagrawal03/TheHackateers-HumanAIze/blob/main/Insurance_frud_interface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl-sB_nRM16b",
        "outputId": "55f1d351-f54a-4e2e-89f3-1957d9455936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lida\n",
            "  Downloading lida-0.0.14-py3-none-any.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llmx>=0.0.21a (from lida)\n",
            "  Downloading llmx-0.0.21a0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from lida) (2.7.0)\n",
            "Collecting uvicorn (from lida)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from lida) (0.9.4)\n",
            "Collecting fastapi (from lida)\n",
            "  Downloading fastapi-0.110.2-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart (from lida)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lida) (1.11.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lida) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lida) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lida) (3.7.1)\n",
            "Requirement already satisfied: altair in /usr/local/lib/python3.10/dist-packages (from lida) (4.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from lida) (0.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from lida) (5.15.0)\n",
            "Requirement already satisfied: plotnine in /usr/local/lib/python3.10/dist-packages (from lida) (0.12.4)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from lida) (0.14.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from lida) (3.3)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (from lida) (0.13.2)\n",
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.10/dist-packages (from lida) (0.11.10)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.10/dist-packages (from lida) (1.9.3)\n",
            "Collecting kaleido!=0.2.1.post1,>=0.2.1 (from lida)\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai (from llmx>=0.0.21a->lida)\n",
            "  Downloading openai-1.23.6-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken (from llmx>=0.0.21a->lida)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diskcache (from llmx>=0.0.21a->lida)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cohere (from llmx>=0.0.21a->lida)\n",
            "  Downloading cohere-5.3.3-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.2/151.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google.auth in /usr/local/lib/python3.10/dist-packages (from llmx>=0.0.21a->lida) (2.27.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from llmx>=0.0.21a->lida) (6.0.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair->lida) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair->lida) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair->lida) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair->lida) (0.12.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->lida) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lida) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lida) (2024.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->lida)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->lida) (4.11.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->lida) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->lida) (2.18.1)\n",
            "Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas->lida) (1.9.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas->lida) (24.0)\n",
            "Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas->lida) (3.6.1)\n",
            "Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from geopandas->lida) (2.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lida) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lida) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lida) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lida) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lida) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lida) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->lida) (8.2.3)\n",
            "Requirement already satisfied: mizani<0.10.0,>0.9.0 in /usr/local/lib/python3.10/dist-packages (from plotnine->lida) (0.9.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from plotnine->lida) (0.5.6)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer->lida) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn->lida)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas->lida) (23.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas->lida) (2024.2.2)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas->lida) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas->lida) (0.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas->lida) (1.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair->lida) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair->lida) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair->lida) (0.18.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.38.0,>=0.37.2->fastapi->lida) (3.7.1)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere->llmx>=0.0.21a->lida)\n",
            "  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.21.2 (from cohere->llmx>=0.0.21a->lida)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx-sse<0.5.0,>=0.4.0 (from cohere->llmx>=0.0.21a->lida)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere->llmx>=0.0.21a->lida) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from cohere->llmx>=0.0.21a->lida) (0.19.1)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere->llmx>=0.0.21a->lida)\n",
            "  Downloading types_requests-2.31.0.20240406-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google.auth->llmx>=0.0.21a->lida) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google.auth->llmx>=0.0.21a->lida) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google.auth->llmx>=0.0.21a->lida) (4.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair->lida) (2.1.5)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->llmx>=0.0.21a->lida) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai->llmx>=0.0.21a->lida) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai->llmx>=0.0.21a->lida) (4.66.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->llmx>=0.0.21a->lida) (2023.12.25)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->lida) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->lida) (1.2.1)\n",
            "Collecting httpcore==1.* (from httpx>=0.21.2->cohere->llmx>=0.0.21a->lida)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google.auth->llmx>=0.0.21a->lida) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere->llmx>=0.0.21a->lida) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere->llmx>=0.0.21a->lida) (2.0.7)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<0.20,>=0.19->cohere->llmx>=0.0.21a->lida) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20,>=0.19->cohere->llmx>=0.0.21a->lida) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20,>=0.19->cohere->llmx>=0.0.21a->lida) (2023.6.0)\n",
            "Installing collected packages: kaleido, types-requests, python-multipart, httpx-sse, h11, fastavro, diskcache, uvicorn, tiktoken, starlette, httpcore, httpx, fastapi, openai, cohere, llmx, lida\n",
            "Successfully installed cohere-5.3.3 diskcache-5.6.3 fastapi-0.110.2 fastavro-1.9.4 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 httpx-sse-0.4.0 kaleido-0.2.1 lida-0.0.14 llmx-0.0.21a0 openai-1.23.6 python-multipart-0.0.9 starlette-0.37.2 tiktoken-0.6.0 types-requests-2.31.0.20240406 uvicorn-0.29.0\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.110.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.7.0)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.37.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.11.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.18.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.38.0,>=0.37.2->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (1.2.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.7.0)\n",
            "Collecting pydantic\n",
            "  Downloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.6.0)\n",
            "Collecting pydantic-core==2.18.2 (from pydantic)\n",
            "  Downloading pydantic_core-2.18.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.11.0)\n",
            "Installing collected packages: pydantic-core, pydantic\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.18.1\n",
            "    Uninstalling pydantic_core-2.18.1:\n",
            "      Successfully uninstalled pydantic_core-2.18.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.7.0\n",
            "    Uninstalling pydantic-2.7.0:\n",
            "      Successfully uninstalled pydantic-2.7.0\n",
            "Successfully installed pydantic-2.7.1 pydantic-core-2.18.2\n",
            "Requirement already satisfied: pydantic-core in /usr/local/lib/python3.10/dist-packages (2.18.2)\n",
            "Requirement already satisfied: typing-extensions!=4.7.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-core) (4.11.0)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Collecting tensorflow-probability\n",
            "  Downloading tensorflow_probability-0.24.0-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.25.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (0.5.4)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (0.1.8)\n",
            "Installing collected packages: tensorflow-probability\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.23.0\n",
            "    Uninstalling tensorflow-probability-0.23.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.23.0\n",
            "Successfully installed tensorflow-probability-0.24.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade lida\n",
        "!pip install --upgrade fastapi\n",
        "!pip install --upgrade pydantic\n",
        "!pip install --upgrade pydantic-core\n",
        "!pip install --upgrade tensorflow-probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90j7d2Vtk0Rp",
        "outputId": "edaa4c25-0a4a-4757-bc0a-d4ce9c53ec56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting typing-extensions==3.10.0.2\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.11.0\n",
            "    Uninstalling typing_extensions-4.11.0:\n",
            "      Successfully uninstalled typing_extensions-4.11.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.2.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "sqlalchemy 2.0.29 requires typing-extensions>=4.6.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "arviz 0.15.1 requires typing-extensions>=4.1.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "chex 0.1.86 requires typing-extensions>=4.2.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "cloudpathlib 0.16.0 requires typing_extensions>4; python_version < \"3.11\", but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "cohere 5.3.3 requires typing_extensions>=4.0.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "fastapi 0.110.2 requires typing-extensions>=4.8.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "flax 0.8.2 requires typing-extensions>=4.2, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "ibis-framework 8.0.0 requires typing-extensions<5,>=4.3.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "librosa 0.10.1 requires typing-extensions>=4.1.1, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "openai 1.23.6 requires typing-extensions<5,>=4.7, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "pydantic 2.7.1 requires typing-extensions>=4.6.1, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "pydantic-core 2.18.2 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "python-utils 3.8.2 requires typing-extensions>3.10.0.2, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "torch 2.2.1+cu121 requires typing-extensions>=4.8.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "uvicorn 0.29.0 requires typing-extensions>=4.0; python_version < \"3.11\", but you have typing-extensions 3.10.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typing-extensions-3.10.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install typing-extensions==3.10.0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31xKnGEnM_sG",
        "outputId": "3ba86148-8ae0-45ce-d042-80c4272310f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfTnxdRQNAYv"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjaAG2wGNO59",
        "outputId": "fadd63a8-f02e-4250-c5a1-1f1f29e2425b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "rfc = joblib.load('/content/drive/MyDrive/Colab Notebooks/trained_model.pkl')\n",
        "scaler = joblib.load('/content/drive/MyDrive/Colab Notebooks/scaler_filename.pkl')\n",
        "preprocessor = joblib.load('/content/drive/MyDrive/Colab Notebooks/preprocessor.joblib')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xwkmdoNQlFxI"
      },
      "outputs": [],
      "source": [
        "def predict_fraud(Make, AccidentArea, Sex, Age, MaritalStatus, PolicyType,\n",
        "       VehiclePrice, Deductible, DriverRating, PastNumberOfClaims,\n",
        "       AgeOfVehicle, PoliceReportFiled, WitnessPresent, AgentType,\n",
        "       NumberOfCars):\n",
        "\n",
        "    # Create test data as a DataFrame\n",
        "    test_data = pd.DataFrame({\n",
        "        'Make': [Make],\n",
        "        'AccidentArea': [AccidentArea],\n",
        "        'Sex': [Sex],\n",
        "        'Age': [Age],\n",
        "        'MaritalStatus': [MaritalStatus],\n",
        "        'PolicyType': [PolicyType],\n",
        "        'VehiclePrice': [VehiclePrice],\n",
        "        'Deductible': [Deductible],\n",
        "        'DriverRating': [DriverRating],\n",
        "        'PastNumberOfClaims': [PastNumberOfClaims],\n",
        "        'AgeOfVehicle': [AgeOfVehicle],\n",
        "        'PoliceReportFiled': [PoliceReportFiled],\n",
        "        'WitnessPresent': [WitnessPresent],\n",
        "        'AgentType': [AgentType],\n",
        "        'NumberOfCars': [NumberOfCars]\n",
        "    })\n",
        "    # Assuming test_data is your DataFrame with categorical columns\n",
        "    categorical_cols = test_data[['Make', 'AccidentArea', 'Sex', 'MaritalStatus', 'PolicyType',\n",
        "                                'VehiclePrice', 'PastNumberOfClaims', 'AgeOfVehicle',\n",
        "                                'PoliceReportFiled', 'WitnessPresent', 'AgentType', 'NumberOfCars']]\n",
        "\n",
        "# Assuming you have new_data which has similar categorical columns\n",
        "    X_processed = preprocessor.transform(categorical_cols)\n",
        "    ohe_column_names = preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_cols.columns)\n",
        "\n",
        "# Convert the sparse matrix to a DataFrame with column names\n",
        "    X_processed = pd.DataFrame.sparse.from_spmatrix(X_processed, columns=ohe_column_names)\n",
        "\n",
        "\n",
        "# Now, new_data_encoded has the same one-hot encoding as the loaded_categorical_cols\n",
        "\n",
        "    numerical_cols = test_data[['Age', 'Deductible', 'DriverRating']]\n",
        "\n",
        "    # Select numerical columns\n",
        "    x = pd.concat([numerical_cols.reset_index(drop=True), X_processed.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    x[[ 'Age', 'Deductible',  'DriverRating']]=scaler.transform(x[['Age', 'Deductible',  'DriverRating']])\n",
        "\n",
        "\n",
        "    # Combine numerical and categorical columns\n",
        "\n",
        "    predicted_label = rfc.predict(x)\n",
        "\n",
        "    if predicted_label[0] == 1:\n",
        "        output_label = \"Fraud Detected\"\n",
        "    else:\n",
        "        output_label = \"No Fraud Detected\"\n",
        "    return output_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "QuzisgeY6CYR",
        "outputId": "f4d76817-9c8b-420b-b624-b1f5cfa30b0d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://589c88744a8049629e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://589c88744a8049629e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://589c88744a8049629e.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Define the dropdowns\n",
        "dropdowns = [\n",
        "    gr.Dropdown(\n",
        "        ['Pontiac', 'Toyota', 'Saturn', 'Ferrari', 'Jaguar', 'VW', 'Lexus', 'Honda', 'Ford', 'Accura', 'BMW', 'Mazda', 'Nisson', 'Chevrolet', 'Mercury', 'Porche', 'Mecedes', 'Saab', 'Dodge'], label=\"Make of the Vehicle\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        ['Urban', 'Rural'], label=\"Accident Area\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        ['Male', 'Female'], label=\"Sex\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        ['16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37',\n",
        "         '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59','60', '61',\n",
        "         '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78','79', '80'], label=\"Age\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        ['Single',  'Married', 'Divorced', 'Widow'], label=\"Marital Status\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        ['Sedan - Liability', 'Sport - Collision', 'Sport - All Perils', 'Utility - All Perils', 'Sport - Liability', 'Utility - Liability',\n",
        "         'Sedan - All Perils', 'Utility - Collision', 'Sedan - Collision'], label=\"Policy Type\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        ['less than 20000', '20000 to 29000' ,'30000 to 39000',  '40000 to 59000',  '60000 to 69000',  'more than 69000' ], label=\"Price of the Vehicle\"\n",
        "    ),\n",
        "     gr.Dropdown(\n",
        "        ['300' ,'400', '500', '700'], label=\"Deductible Amount\", info=\"Select the closest amount\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        ['1', '2', '3', '4'], label=\"Driver Rating\"\n",
        "    ),\n",
        "     gr.Dropdown(\n",
        "        [ 'none', '1', '2 to 4', 'more than 4'], label=\"Past Number of Claims\"\n",
        "    ),\n",
        "     gr.Dropdown(\n",
        "        ['new',  '2 years',  '3 years',  '4 years', '5 years',  '6 years',  '7 years', 'more than 7'], label=\"Age of the Vehicle\"\n",
        "    ),\n",
        "     gr.Dropdown(\n",
        "        [ 'Yes', 'No'], label=\"Was a police report filed?\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        [ 'Yes', 'No'], label=\"Was there any witness present?\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        ['Internal', 'External'], label=\"Agent Type\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        ['1 vehicle','2 vehicles',  '3 to 4', '5 to 8', 'more than 8'], label=\"Number of cars owned\"\n",
        "    )\n",
        "\n",
        "]\n",
        "\n",
        "#Gradio interface with custom layout\n",
        "interface = gr.Interface(\n",
        "    fn=predict_fraud,  # Replace with your prediction function\n",
        "    inputs=dropdowns,\n",
        "    outputs=\"text\",\n",
        "\n",
        ")\n",
        "interface.launch(debug=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "asfyb-sO8Y4I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGmHNZWIdE6mIVYjlPDF3p",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}